{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea42bdff",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456dcbf5",
   "metadata": {},
   "source": [
    "# Token Classification with Large Language Models #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f28cf3",
   "metadata": {},
   "source": [
    "## 01 - Named Entity Recognition with Pre-Trained Model ##\n",
    "\n",
    "In this notebook, you will learn to use a pre-trained token classification model. Specifically, we will use a model for named entity recognition. NER, also referred to as entity chunking, identification or extraction, is the task of detecting and classifying key information (entities) in text. In other words, a NER model takes a piece of text as input and for each word in the text, the model identifies a category the word belongs to. For example, in a sentence: `Mary lives in Santa Clara and works at NVIDIA`, the model should detect that `Mary` is a person, `Santa Clara` is a location and `NVIDIA` is a company.\n",
    "\n",
    "**Table of Contents**<br>\n",
    "This notebook covers the below sections: \n",
    "* Project Overview\n",
    "* Dataset\n",
    "    * Download and Preprocess data\n",
    "    * Labeling Data (OPTIONAL)\n",
    "* Use Pre-Trained Model\n",
    "    * Download Model\n",
    "    * Make Predictions\n",
    "    * Model Evaluation\n",
    "* Fine-Tune a Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d0652",
   "metadata": {},
   "source": [
    "## Project Overview ##\n",
    "\n",
    "<img src='images/workflow.png' width=1080>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad62d3",
   "metadata": {},
   "source": [
    "## Dataset ##\n",
    "For this notebook, we're going to use the [GMB (Groningen Meaning Bank)](http://www.let.rug.nl/bjerva/gmb/about.php) corpus for named entity recognition. GMB is a fairly large corpus with a lot of annotations. The data is labeled using the [IOB format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (short for inside, outside, beginning), which means each annotation also needs a prefix of **I**, **O**, or **B**. \n",
    "\n",
    "The following classes appear in the dataset:\n",
    "* **LOC** - Geographical Entity\n",
    "* **ORG** - Organization\n",
    "* **PER** - Person\n",
    "* **GPE** - Geopolitical Entity\n",
    "* **TIME** - Time indicator\n",
    "* **ART** - Artifact\n",
    "* **EVE** - Event\n",
    "* **NAT** - Natural Phenomenon\n",
    "\n",
    "_Note:_ GMB is not completely human annotated, and itâ€™s not considered 100% correct. For this exercise, classes **ART**, **EVE**, and **NAT** were combined into a **MISC** class due to small number of examples for these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68300249",
   "metadata": {},
   "source": [
    "For token classification tasks, NeMo requires the data to be in a specific format. Data needs to be split into  files: \n",
    "* `text.txt` and \n",
    "* `labels.txt`\n",
    "\n",
    "Each line of the **text.txt** file contains text sequences, where words are separated with spaces, i.e.: `[WORD] [SPACE] [WORD] [SPACE] [WORD]`. The **labels.txt** file contains corresponding labels for each word in **text.txt**, the labels are separated with spaces, i.e.: `[LABEL] [SPACE] [LABEL] [SPACE] [LABEL]`.\n",
    "\n",
    "For example: \n",
    "* **text.txt**\n",
    "```\n",
    "Jennifer is from New York City .\n",
    "She likes ...\n",
    "...\n",
    "```\n",
    "* **labels.txt**\n",
    "```\n",
    "B-PER O O B-LOC I-LOC I-LOC O\n",
    "O O ...\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff788f",
   "metadata": {},
   "source": [
    "### Download and Preprocess Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688aa1f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import wget\n",
    "\n",
    "# set data path\n",
    "DATA_DIR=\"data/GMB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb714a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check that data folder should contain 4 files\n",
    "!ls -l $DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0684f72f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview data \n",
    "print('Text:')\n",
    "!head -n 5 {DATA_DIR}/text_train.txt\n",
    "\n",
    "print('Labels:')\n",
    "!head -n 5 {DATA_DIR}/labels_train.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f0dff5",
   "metadata": {},
   "source": [
    "### Labeling Data ###\n",
    "\n",
    "If you have raw data, NeMo recommends using the [Datasaur](https://datasaur.ai/) labeling platform to apply labels to data. Datasaur was designed specifically for labeling text data and supports basic NLP labeling tasks such as Named Entity Recognition and text classification through advanced NLP tasks such as dependency parsing and coreference resolution. You can sign up for Datasaur for free at https://datasaur.ai/sign-up/. Once you upload a file, you can choose from multiple NLP project types and use the Datasaur interface to label the data. After labeling, you can export the labeled data using the conll_2003 format, which integrates directly with NeMo. A video walkthrough can be found [here](https://www.youtube.com/watch?v=I9WVmnnSciE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735127d",
   "metadata": {},
   "source": [
    "## Use Pre-Trained Model ##\n",
    "NeMo supports NER and other token-level classification tasks. These models typically comprise of a pre-trained [BERT](https://arxiv.org/pdf/1810.04805.pdf) model followed by a token classification layer. We start by using a pre-trained model. The `TokenClassificationModel` inherits from `NLPModel` and has the below methods: \n",
    "* `TokenClassificationModel.add_predictions()`\n",
    "* `TokenClassificationModel.evaluate_from_file()`\n",
    "\n",
    "These are useful when making inference and evaluating model performance. Additional functionality of the `TokenClassificationModel` can be found in the [source code](https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/nlp/models/token_classification/token_classification_model.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a98fc74",
   "metadata": {},
   "source": [
    "### Download Pre-Trained Model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b9c6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from nemo.collections.nlp.models import TokenClassificationModel\n",
    "\n",
    "# list available pre-trained models\n",
    "for model in TokenClassificationModel.list_available_models():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225bd9c3",
   "metadata": {},
   "source": [
    "_Note:_ These are models trained for token classification. To get a list of all supported models, use `nemo.collections.nlp.modules.get_pretrained_lm_models_list(include_external=True)`. The list of pre-trained models is expected to change as they become available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a6a99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download and load the pre-trained BERT-based model\n",
    "pretrained_ner_model=TokenClassificationModel.from_pretrained(\"ner_en_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44a9806",
   "metadata": {},
   "source": [
    "### Make Predictions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962e83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the list of queries for inference\n",
    "queries=[\n",
    "    'we bought four shirts from the nvidia gear store in santa clara.',\n",
    "    'Nvidia is a company.',\n",
    "]\n",
    "\n",
    "# make sample predictions\n",
    "results=pretrained_ner_model.add_predictions(queries)\n",
    "\n",
    "# show predictions\n",
    "for query, result in zip(queries, results):\n",
    "    print(f'Query : {query}')\n",
    "    print(f'Result: {result.strip()}\\n')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14841924",
   "metadata": {},
   "source": [
    "### Evaluate Predictions ###\n",
    "\n",
    "To see how the model performs, we can generate predictions similar to the way we did it before and compare it with the labels. Alternatively, the `evaluate_from_file()` method enables us to evaluate the model given `text_file` and `labels_file`. Optionally, you can use the `add_confusion_matrix` to get a visual representation of the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f4dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset of our dev data\n",
    "!head -n 100 $DATA_DIR/text_dev.txt > $DATA_DIR/sample_text_dev.txt\n",
    "!head -n 100 $DATA_DIR/labels_dev.txt > $DATA_DIR/sample_labels_dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c2e358",
   "metadata": {},
   "source": [
    "Now, let's generate predictions for the provided text file. If labels file is also specified, the model will evaluate the predictions and plot confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1364fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WORK_DIR = \"WORK_DIR\"\n",
    "\n",
    "# evaluate model performance on sample\n",
    "pretrained_ner_model.evaluate_from_file(\n",
    "    text_file=os.path.join(DATA_DIR, 'sample_text_dev.txt'),\n",
    "    labels_file=os.path.join(DATA_DIR, 'sample_labels_dev.txt'),\n",
    "    output_dir=WORK_DIR,\n",
    "    add_confusion_matrix=True,\n",
    "    normalize_confusion_matrix=True,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5ae86",
   "metadata": {},
   "source": [
    "## Fine-Tune a Pre-Trained Model ##\n",
    "\n",
    "Without specifying configuration file, NeMo will use the default configurations for the model and trainer. When fine-tuning a pre-trained NER model, we need to setup training and evaluation data before training, the dataset directory is the only required argument if the files names are `labels_dev.txt`, `labels_train.txt`, `text_dev.txt`, and `text_train.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e4efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "\n",
    "# setup the data dir to get class weights statistics\n",
    "pretrained_ner_model.update_data_dir(DATA_DIR)\n",
    "\n",
    "# setup train and validation Pytorch DataLoaders\n",
    "pretrained_ner_model.setup_training_data()\n",
    "pretrained_ner_model.setup_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0316a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up loss\n",
    "pretrained_ner_model.setup_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09865519",
   "metadata": {},
   "source": [
    "_Note:_ Use `class_balancing='weighted_loss'` if you want to add class weights to the `CrossEntropyLoss`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7fef0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a PyTorch Lightning trainer and call `fit` again\n",
    "fast_dev_run=True\n",
    "trainer=pl.Trainer(devices=1, accelerator='gpu', fast_dev_run=fast_dev_run)\n",
    "trainer.fit(pretrained_ner_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ad95a",
   "metadata": {},
   "source": [
    "_Note:_ When training a model, we can set up the model (and trainer) using a configuration file. This is not needed since the task we are performing is the same as the pre-trained model. We will train a custom token classification model in the next notebook, which will require using a configuration file. Furthermore, we are setting `fast_dev_run` to `True` for this demonstration so the trainer will run 1 training batch and 1 validation batch. For actual model training, disable the flag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46020a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate model performance on sample\n",
    "pretrained_ner_model.evaluate_from_file(\n",
    "    text_file=os.path.join(DATA_DIR, 'sample_text_dev.txt'),\n",
    "    labels_file=os.path.join(DATA_DIR, 'sample_labels_dev.txt'),\n",
    "    output_dir=WORK_DIR,\n",
    "    add_confusion_matrix=True,\n",
    "    normalize_confusion_matrix=True,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ea3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart the kernel\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398c73b",
   "metadata": {},
   "source": [
    "**Well Done!** When you're ready, let's move to the [next notebook](./02_domain-specific_token_classification_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570750c7",
   "metadata": {},
   "source": [
    "![DLI Header](images/DLI_Header.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
